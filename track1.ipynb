{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d042f12",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Load data\n",
    "# ----------------\n",
    "# Read CSVs into pandas DataFrames. 'test' has no labels.\n",
    "train = pd.read_csv(\"train.csv\")  # Training set with labels\n",
    "dev = pd.read_csv(\"dev.csv\")      # Development set with labels\n",
    "test = pd.read_csv(\"test.csv\")    # Test set without labels\n",
    "\n",
    "# 2. Vectorize text\n",
    "# --------------------\n",
    "# Convert raw text into TF-IDF feature vectors.\n",
    "# - ngram_range=(2,6): consider character n-grams of length 2 to 6.\n",
    "# - min_df=5: ignore infrequent n-grams to reduce noise.\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,6), min_df=5)\n",
    "X_train = vectorizer.fit_transform(train['text'])\n",
    "y_train = train['label']\n",
    "X_dev = vectorizer.transform(dev['text'])\n",
    "y_dev = dev['label']\n",
    "X_test = vectorizer.transform(test['text'])\n",
    "\n",
    "# 3. Hyperparameter tuning with progress bar\n",
    "# --------------------------------------------\n",
    "# Define grid of Random Forest hyperparameters:\n",
    "# - n_estimators: number of trees in the forest\n",
    "# - max_depth: maximum depth of each tree\n",
    "# - max_features: number of features to consider at each split\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 500],\n",
    "#     'max_depth': [None, 10, 20],\n",
    "#     'max_features': ['sqrt', 'log2', 0.3]\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': None,\n",
    "    'max_features': 'sqrt'\n",
    "}\n",
    "\n",
    "# Create a list of all parameter combinations\n",
    "import itertools\n",
    "param_list = list(itertools.product(\n",
    "    param_grid['n_estimators'],\n",
    "    param_grid['max_depth'],\n",
    "    param_grid['max_features']\n",
    "))\n",
    "\n",
    "best_score = 0\n",
    "best_params = None\n",
    "print(\"Tuning Random Forest hyperparameters:\")\n",
    "for n_est, depth, feat in tqdm(param_list, desc=\"Grid Search\", unit=\"combo\"):\n",
    "    # Initialize a Random Forest with current hyperparameters\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        max_features=feat,\n",
    "        oob_score=False,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    # 3-fold cross-validation for macro-F1 on TRAIN\n",
    "    scores = cross_val_score(\n",
    "        rf, X_train, y_train,\n",
    "        scoring='f1_macro',\n",
    "        cv=3,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    mean_score = scores.mean()\n",
    "    # Update best parameters if current is better\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth, 'max_features': feat}\n",
    "\n",
    "print(f\"\\nBest params: {best_params} with CV macro-F1 = {best_score:.4f}\")\n",
    "\n",
    "# 4. Train best Random Forest on full TRAIN set\n",
    "# ------------------------------------------------\n",
    "best_rf = RandomForestClassifier(\n",
    "    **best_params,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluate on DEV set\n",
    "# -----------------------\n",
    "dev_preds = best_rf.predict(X_dev)\n",
    "print(\"DEV Macro F1:\", f1_score(y_dev, dev_preds, average='macro'))\n",
    "\n",
    "# 6. (Optional) Retrain on TRAIN + DEV and predict TEST\n",
    "# ------------------------------------------------------\n",
    "# all_texts = pd.concat([train['text'], dev['text']])\n",
    "# all_labels = pd.concat([train['label'], dev['label']])\n",
    "# X_all = vectorizer.fit_transform(all_texts)\n",
    "# best_rf.fit(X_all, all_labels)\n",
    "# test_preds = best_rf.predict(X_test)\n",
    "# submission = pd.DataFrame({'id': test['id'], 'label': test_preds})\n",
    "# submission.to_csv('track_1_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640cc164",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Load data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "dev = pd.read_csv(\"dev.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# 2. Vectorize text\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,6), min_df=5)\n",
    "X_train = vectorizer.fit_transform(train['text'])\n",
    "y_train = train['label']\n",
    "X_dev = vectorizer.transform(dev['text'])\n",
    "y_dev = dev['label']\n",
    "\n",
    "# 3. Define a single set of RF hyperparameters\n",
    "# We'll start with a common default: 200 trees, no max depth, sqrt features\n",
    "rf_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': None,\n",
    "    'max_features': 'sqrt'\n",
    "}\n",
    "print(f\"Training Random Forest with params: {rf_params}\")\n",
    "\n",
    "# 4. Quick cross-validation to estimate performance\n",
    "rf = RandomForestClassifier(\n",
    "    **rf_params,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "# 3-fold CV on training set\n",
    "cv_scores = cross_val_score(rf, X_train, y_train, scoring='f1_macro', cv=3, n_jobs=-1)\n",
    "print(f\"CV Macro F1 scores: {cv_scores}\")\n",
    "print(f\"Mean CV Macro F1: {cv_scores.mean():.4f}\")\n",
    "\n",
    "# 5. Train on full training set and evaluate on DEV set\n",
    "rf.fit(X_train, y_train)\n",
    "dev_preds = rf.predict(X_dev)\n",
    "print(\"DEV Macro F1:\", f1_score(y_dev, dev_preds, average='macro'))\n",
    "\n",
    "# 6. (Optional) Retrain on TRAIN+DEV and predict TEST\n",
    "# all_texts = pd.concat([train['text'], dev['text']])\n",
    "# all_labels = pd.concat([train['label'], dev['label']])\n",
    "# X_all = vectorizer.fit_transform(all_texts)\n",
    "# rf.fit(X_all, all_labels)\n",
    "# test_preds = rf.predict(vectorizer.transform(test['text']))\n",
    "# submission = pd.DataFrame({'id': test['id'], 'label': test_preds})\n",
    "# submission.to_csv('track_1_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d25634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning regularization strength C:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search - C values: 100%|██████████| 4/4 [00:09<00:00,  2.49s/value]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best C found: 1 with CV macro-F1 = 0.3164\n",
      "DEV Macro F1: 0.3149562265024328\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Load data\n",
    "# ----------------\n",
    "train = pd.read_csv(\"train.csv\")  # Training set\n",
    "dev = pd.read_csv(\"dev.csv\")      # Development/validation set\n",
    "test = pd.read_csv(\"test.csv\")    # Test set (unlabeled)\n",
    "\n",
    "# 2. Vectorize text\n",
    "# --------------------\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,6), min_df=5)\n",
    "X_train = vectorizer.fit_transform(train['text'])\n",
    "y_train = train['label']\n",
    "X_dev = vectorizer.transform(dev['text'])\n",
    "y_dev = dev['label']\n",
    "X_test = vectorizer.transform(test['text'])\n",
    "\n",
    "# 3. Manual hyperparameter tuning with progress bar\n",
    "# ---------------------------------------------------\n",
    "# Define grid of regularization strengths\n",
    "param_C = [0.01, 0.1, 1, 10]\n",
    "best_score = 0\n",
    "best_C = None\n",
    "print(\"Tuning regularization strength C:\")\n",
    "for C in tqdm(param_C, desc=\"Grid Search - C values\", unit=\"value\"):\n",
    "    # Initialize model with current C\n",
    "    lr = LogisticRegression(\n",
    "        penalty='l2',\n",
    "        solver='saga',\n",
    "        max_iter=1000,\n",
    "        C=C,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    # Perform 3-fold CV on training set, scoring macro-F1\n",
    "    scores = cross_val_score(\n",
    "        lr, X_train, y_train,\n",
    "        scoring='f1_macro',\n",
    "        cv=3,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    mean_score = scores.mean()\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_C = C\n",
    "        best_scores = scores\n",
    "\n",
    "print(f\"\\nBest C found: {best_C} with CV macro-F1 = {best_score:.4f}\")\n",
    "\n",
    "# Train best model on full TRAIN\n",
    "best_lr = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    "    C=best_C,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "best_lr.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate on DEV set\n",
    "# -----------------------\n",
    "dev_preds = best_lr.predict(X_dev)\n",
    "print(\"DEV Macro F1:\", f1_score(y_dev, dev_preds, average='macro'))\n",
    "\n",
    "# 5. (Optional) Retrain on TRAIN + DEV and predict TEST\n",
    "# ------------------------------------------------------\n",
    "# all_texts = pd.concat([train['text'], dev['text']])\n",
    "# all_labels = pd.concat([train['label'], dev['label']])\n",
    "# X_all = vectorizer.fit_transform(all_texts)\n",
    "# best_lr.fit(X_all, all_labels)\n",
    "# test_preds = best_lr.predict(X_test)\n",
    "\n",
    "# # Save submission\n",
    "# submission = pd.DataFrame({'id': test['id'], 'label': test_preds})\n",
    "# submission.to_csv('track_1_test.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
