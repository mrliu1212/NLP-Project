{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fa49a84d",
      "metadata": {},
      "source": [
        "# TFIDF + Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "149ee4b7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Macro F1 Score: 0.4114\n",
            "Saved Track 1 submission to outputs/track_1_test.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv('../data/train.csv')\n",
        "dev_df = pd.read_csv('../data/dev.csv')\n",
        "test_df = pd.read_csv('../data/test.csv')\n",
        "\n",
        "# Preprocessing\n",
        "\n",
        "# Combine train and dev for vectorizer fitting\n",
        "full_train_texts = train_df['text'].tolist() + dev_df['text'].tolist()\n",
        "full_train_labels = train_df['label'].tolist() + dev_df['label'].tolist()\n",
        "\n",
        "# Mapping labels to ids\n",
        "labels = list(sorted(set(full_train_labels)))\n",
        "label2id = {label: idx for idx, label in enumerate(labels)}\n",
        "id2label = {idx: label for label, idx in label2id.items()}\n",
        "\n",
        "y_train = [label2id[label] for label in train_df['label']]\n",
        "y_dev = [label2id[label] for label in dev_df['label']]\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfVectorizer(\n",
        "    analyzer='char_wb',   # character n-grams inside word boundaries\n",
        "    ngram_range=(2,6),    # 2-6 character n-grams\n",
        "    max_features=50000    # limit vocabulary size\n",
        ")\n",
        "\n",
        "# Fit on training + dev set\n",
        "tfidf.fit(full_train_texts)\n",
        "\n",
        "# Transform\n",
        "X_train = tfidf.transform(train_df['text'])\n",
        "X_dev = tfidf.transform(dev_df['text'])\n",
        "X_test = tfidf.transform(test_df['text'])\n",
        "\n",
        "# Train Logistic Regression\n",
        "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on Dev Set\n",
        "dev_preds = clf.predict(X_dev)\n",
        "dev_macro_f1 = f1_score(y_dev, dev_preds, average='macro')\n",
        "print(f\"Validation Macro F1 Score: {dev_macro_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5aa6c9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on Test Set\n",
        "test_preds = clf.predict(X_test)\n",
        "test_labels = [id2label[pred] for pred in test_preds]\n",
        "\n",
        "# Save to CSV\n",
        "output_df = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'label': test_labels\n",
        "})\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "output_df.to_csv('outputs/track_1_test.csv', index=False)\n",
        "\n",
        "print(\"Saved Track 1 submission to outputs/track_1_test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d40a55c3",
      "metadata": {},
      "source": [
        "# TFIDF + Elastic Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da6802e8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting model\n",
            "Evaluation model\n",
            "Validation Macro F1 Score (retrained best model): 0.4261\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import ParameterGrid, cross_val_score\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv('../data/train.csv')\n",
        "dev_df = pd.read_csv('../data/dev.csv')\n",
        "test_df = pd.read_csv('../data/test.csv')\n",
        "\n",
        "# Preprocessing\n",
        "full_train_texts = train_df['text'].tolist() + dev_df['text'].tolist()\n",
        "full_train_labels = train_df['label'].tolist() + dev_df['label'].tolist()\n",
        "\n",
        "labels = list(sorted(set(full_train_labels)))\n",
        "label2id = {label: idx for idx, label in enumerate(labels)}\n",
        "id2label = {idx: label for label, idx in label2id.items()}\n",
        "\n",
        "y_train = [label2id[label] for label in train_df['label']]\n",
        "y_dev = [label2id[label] for label in dev_df['label']]\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfVectorizer(\n",
        "    analyzer='char_wb',\n",
        "    ngram_range=(2,6),\n",
        "    max_features=50000\n",
        ")\n",
        "\n",
        "tfidf.fit(full_train_texts)\n",
        "\n",
        "X_train = tfidf.transform(train_df['text'])\n",
        "X_dev = tfidf.transform(dev_df['text'])\n",
        "X_test = tfidf.transform(test_df['text'])\n",
        "\n",
        "\n",
        "# Too time consuming TODO: Try with cv before submitting\n",
        "# # Hyperparameter Grid\n",
        "# param_grid = {\n",
        "#     'C': [0.01, 10],\n",
        "#     'l1_ratio': [0.3, 0.7]\n",
        "# }\n",
        "# grid = list(ParameterGrid(param_grid))\n",
        "\n",
        "# # Cache file\n",
        "# CACHE_FILE = './cache/ENET_CV5_cache.pkl'\n",
        "\n",
        "# # Load previous cache if exists\n",
        "# if os.path.exists(CACHE_FILE):\n",
        "#     with open(CACHE_FILE, 'rb') as f:\n",
        "#         cache = pickle.load(f)\n",
        "#     print(f\"Loaded {len(cache)} cached results.\")\n",
        "# else:\n",
        "#     cache = {}\n",
        "\n",
        "# best_score = 0\n",
        "# best_params = None\n",
        "\n",
        "# # Define scoring\n",
        "# scorer = make_scorer(f1_score, average='macro')\n",
        "\n",
        "# # Search\n",
        "# for params in tqdm(grid, desc=\"Grid Search with 5-Fold CV\"):\n",
        "#     param_key = tuple(sorted(params.items()))  # make a hashable key\n",
        "\n",
        "#     if param_key in cache:\n",
        "#         macro_f1 = cache[param_key]\n",
        "#     else:\n",
        "#         print(f'Start of parameter tuning: {param_key}')\n",
        "#         model = LogisticRegression(\n",
        "#             penalty='elasticnet',\n",
        "#             solver='saga',\n",
        "#             max_iter=1000,\n",
        "#             random_state=42,\n",
        "#             n_jobs=-1,\n",
        "#             **params\n",
        "#         )\n",
        "#         # Perform 5-Fold CV here!\n",
        "#         scores = cross_val_score(model, X_train, y_train, cv=5, scoring=scorer, n_jobs=-1)\n",
        "#         macro_f1 = np.mean(scores)\n",
        "\n",
        "#         cache[param_key] = macro_f1\n",
        "\n",
        "#         # Save cache every time\n",
        "#         with open(CACHE_FILE, 'wb') as f:\n",
        "#             pickle.dump(cache, f)\n",
        "#         print(f'Cached {param_key}, f1: {macro_f1:.4f}')\n",
        "\n",
        "#     if macro_f1 > best_score:\n",
        "#         best_score = macro_f1\n",
        "#         best_params = params\n",
        "\n",
        "# print(f\"Best parameters: {best_params}\")\n",
        "# print(f\"Best Macro F1 Score (5-Fold CV): {best_score:.4f}\")\n",
        "\n",
        "# Train the best model fully\n",
        "best_model = LogisticRegression(\n",
        "    penalty='elasticnet',\n",
        "    solver='saga',\n",
        "    max_iter=1000,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    C=1,\n",
        "    l1_ratio= 0.3\n",
        "    # **best_params\n",
        ")\n",
        "print(\"Fitting model\")\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate again on Dev Set\n",
        "print(\"Evaluation model\")\n",
        "dev_preds = best_model.predict(X_dev)\n",
        "dev_macro_f1 = f1_score(y_dev, dev_preds, average='macro')\n",
        "print(f\"Validation Macro F1 Score (retrained best model): {dev_macro_f1:.4f}\")\n",
        "# C=1, L1_ratio=0.7 -> 0.4172\n",
        "# C=1, L1_ratio=0.5 -> 0.4222\n",
        "# C=0.5, L1_ratio=0.5 -> 0.4024\n",
        "# C=1, L1_ratio=0.3 -> 0.4261\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db6dd0bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on Test Set\n",
        "test_preds = clf.predict(X_test)\n",
        "test_labels = [id2label[pred] for pred in test_preds]\n",
        "\n",
        "# Save to CSV\n",
        "output_df = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'label': test_labels\n",
        "})\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "output_df.to_csv('outputs/track_1_test.csv', index=False)\n",
        "\n",
        "print(\"Saved Track 1 submission to outputs/track_1_test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b136d0f",
      "metadata": {},
      "source": [
        "# Word2Vec + XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "608eb983",
      "metadata": {},
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "w2v = api.load('word2vec-google-news-300') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "df129979",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 758.5/758.5MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "glove_twitter = api.load('glove-twitter-200')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5c298a66",
      "metadata": {},
      "outputs": [],
      "source": [
        "fast_wiki = api.load('fasttext-wiki-news-subwords-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bbb16e1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Word2Vec model...\n",
            "Word2Vec model loaded.\n",
            "Vectorizing texts...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32000/32000 [00:02<00:00, 11747.66it/s]\n",
            "100%|██████████| 4000/4000 [00:00<00:00, 9016.40it/s]\n",
            "100%|██████████| 4000/4000 [00:00<00:00, 10453.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vectorization complete.\n",
            "Training XGBoost...\n",
            "Validation Macro F1 Score: 0.3570\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"\\nn_estimators=300,\\nlearning_rate=0.1,\\nmax_depth=6,\\n-> 0.3628\\n\\nTwitter\\nn_estimators=300,\\nlearning_rate=0.1,\\nmax_depth=6,\\n-> 0.3235\\n\\n\\nn_estimators=500,\\nlearning_rate=0.5,\\nmax_depth=8,\\n-> 0.3645\\n\\n'n_estimators': [300, 500],\\n'max_depth': [4, 6, 8],\\n'learning_rate': [0.01, 0.05, 0.1],\\n'subsample': [0.7, 0.8, 1.0],\\n'colsample_bytree': [0.7, 0.8, 1.0]\\n\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv('../data/train.csv')\n",
        "dev_df = pd.read_csv('../data/dev.csv')\n",
        "test_df = pd.read_csv('../data/test.csv')\n",
        "\n",
        "# Preprocessing\n",
        "\n",
        "# Combine train and dev for label mapping\n",
        "full_train_labels = train_df['label'].tolist() + dev_df['label'].tolist()\n",
        "\n",
        "# Map labels to integers\n",
        "labels = list(sorted(set(full_train_labels)))\n",
        "label2id = {label: idx for idx, label in enumerate(labels)}\n",
        "id2label = {idx: label for label, idx in label2id.items()}\n",
        "\n",
        "y_train = [label2id[label] for label in train_df['label']]\n",
        "y_dev = [label2id[label] for label in dev_df['label']]\n",
        "\n",
        "# Load pre-trained Word2Vec embeddings\n",
        "print(\"Loading Word2Vec model...\")\n",
        "w2v = fast_wiki # This is 300-dim Google News vectors\n",
        "print(\"Word2Vec model loaded.\")\n",
        "\n",
        "embedding_dim = 300\n",
        "\n",
        "# Function to vectorize text\n",
        "def text_to_vector(text, model, dim):\n",
        "    words = text.split()\n",
        "    word_vectors = []\n",
        "    for word in words:\n",
        "        if word in model:\n",
        "            word_vectors.append(model[word])\n",
        "    if word_vectors:\n",
        "        return np.mean(word_vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(dim)\n",
        "\n",
        "# Vectorize train, dev, and test sets\n",
        "print(\"Vectorizing texts...\")\n",
        "\n",
        "X_train = np.vstack([text_to_vector(text, w2v, embedding_dim) for text in tqdm(train_df['text'])])\n",
        "X_dev = np.vstack([text_to_vector(text, w2v, embedding_dim) for text in tqdm(dev_df['text'])])\n",
        "X_test = np.vstack([text_to_vector(text, w2v, embedding_dim) for text in tqdm(test_df['text'])])\n",
        "\n",
        "print(\"Vectorization complete.\")\n",
        "\n",
        "# Train XGBoost Classifier\n",
        "print(\"Training XGBoost...\")\n",
        "\n",
        "model = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=len(labels),\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on Dev Set\n",
        "dev_preds = model.predict(X_dev)\n",
        "dev_macro_f1 = f1_score(y_dev, dev_preds, average='macro')\n",
        "print(f\"Validation Macro F1 Score: {dev_macro_f1:.4f}\")\n",
        "\n",
        "# # Predict on Test Set\n",
        "# test_preds = model.predict(X_test)\n",
        "# test_labels = [id2label[pred] for pred in test_preds]\n",
        "\n",
        "# # Save submission\n",
        "# output_df = pd.DataFrame({\n",
        "#     'id': test_df['id'],\n",
        "#     'label': test_labels\n",
        "# })\n",
        "# os.makedirs('outputs', exist_ok=True)\n",
        "# output_df.to_csv('outputs/track_3_test.csv', index=False)\n",
        "\n",
        "# print(\"Saved Track 3 submission to outputs/track_3_test.csv\")\n",
        "\n",
        "\"\"\"\n",
        "n_estimators=300,\n",
        "learning_rate=0.1,\n",
        "max_depth=6,\n",
        "-> 0.3628\n",
        "\n",
        "n_estimators=500,\n",
        "learning_rate=0.5,\n",
        "max_depth=8,\n",
        "-> 0.3645\n",
        "\n",
        "Twitter\n",
        "n_estimators=300,\n",
        "learning_rate=0.1,\n",
        "max_depth=6,\n",
        "-> 0.3235\n",
        "\n",
        "Fast\n",
        "n_estimators=300,\n",
        "learning_rate=0.1,\n",
        "max_depth=6,\n",
        "-> 0.3570\n",
        "\n",
        "\n",
        "\n",
        "'n_estimators': [300, 500],\n",
        "'max_depth': [4, 6, 8],\n",
        "'learning_rate': [0.01, 0.05, 0.1],\n",
        "'subsample': [0.7, 0.8, 1.0],\n",
        "'colsample_bytree': [0.7, 0.8, 1.0]\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abd4e2c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim.downloader as api\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv('../data/train.csv')\n",
        "dev_df = pd.read_csv('../data/dev.csv')\n",
        "test_df = pd.read_csv('../data/test.csv')\n",
        "\n",
        "# Preprocessing\n",
        "\n",
        "full_train_labels = train_df['label'].tolist() + dev_df['label'].tolist()\n",
        "\n",
        "labels = list(sorted(set(full_train_labels)))\n",
        "label2id = {label: idx for idx, label in enumerate(labels)}\n",
        "id2label = {idx: label for idx, label in label2id.items()}\n",
        "\n",
        "y_train = [label2id[label] for label in train_df['label']]\n",
        "y_dev = [label2id[label] for label in dev_df['label']]\n",
        "\n",
        "# Load pre-trained Word2Vec embeddings\n",
        "print(\"Loading Word2Vec model...\")\n",
        "w2v = api.load('word2vec-google-news-300')  # Pretrained 300d embeddings\n",
        "print(\"Word2Vec model loaded.\")\n",
        "\n",
        "embedding_dim = 300\n",
        "\n",
        "# Function to vectorize text\n",
        "def text_to_vector(text, model, dim):\n",
        "    words = text.split()\n",
        "    word_vectors = []\n",
        "    for word in words:\n",
        "        if word in model:\n",
        "            word_vectors.append(model[word])\n",
        "    if word_vectors:\n",
        "        return np.mean(word_vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(dim)\n",
        "\n",
        "# Vectorize train, dev, and test sets (with Cache)\n",
        "CACHE_FOLDER = 'cache'\n",
        "os.makedirs(CACHE_FOLDER, exist_ok=True)\n",
        "\n",
        "def get_cached_vectors(filename, texts):\n",
        "    filepath = os.path.join(CACHE_FOLDER, filename)\n",
        "    if os.path.exists(filepath):\n",
        "        print(f\"Loading cached vectors from {filepath}...\")\n",
        "        return np.load(filepath)\n",
        "    else:\n",
        "        print(f\"Vectorizing and caching {filename}...\")\n",
        "        vectors = np.vstack([text_to_vector(text, w2v, embedding_dim) for text in tqdm(texts)])\n",
        "        np.save(filepath, vectors)\n",
        "        return vectors\n",
        "\n",
        "X_train = get_cached_vectors('train_vectors.npy', train_df['text'])\n",
        "X_dev = get_cached_vectors('dev_vectors.npy', dev_df['text'])\n",
        "X_test = get_cached_vectors('test_vectors.npy', test_df['text'])\n",
        "\n",
        "print(\"Vectorization complete.\")\n",
        "\n",
        "# Cache or train best XGBoost model\n",
        "BEST_MODEL_CACHE = os.path.join(CACHE_FOLDER, 'xgb_best_model.pkl')\n",
        "\n",
        "if os.path.exists(BEST_MODEL_CACHE):\n",
        "    print(f\"Loading best model from cache {BEST_MODEL_CACHE}...\")\n",
        "    with open(BEST_MODEL_CACHE, 'rb') as f:\n",
        "        best_model = pickle.load(f)\n",
        "else:\n",
        "    print(\"Starting hyperparameter tuning with GridSearchCV...\")\n",
        "\n",
        "    xgb_model = xgb.XGBClassifier(\n",
        "        objective='multi:softmax',\n",
        "        num_class=len(labels),\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbosity=0\n",
        "    )\n",
        "\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 300],\n",
        "        '   ': [0.05, 0.1],\n",
        "        'max_depth': [4, 6, 8]\n",
        "    }\n",
        "\n",
        "    grid = GridSearchCV(\n",
        "        estimator=xgb_model,\n",
        "        param_grid=param_grid,\n",
        "        cv=5,\n",
        "        scoring='f1_macro',\n",
        "        verbose=2,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best Params: {grid.best_params_}\")\n",
        "    print(f\"Best CV Macro F1: {grid.best_score_:.4f}\")\n",
        "\n",
        "    best_model = grid.best_estimator_\n",
        "\n",
        "    # Save best model to cache\n",
        "    with open(BEST_MODEL_CACHE, 'wb') as f:\n",
        "        pickle.dump(best_model, f)\n",
        "    print(f\"Saved best model to {BEST_MODEL_CACHE}\")\n",
        "\n",
        "# Evaluate on Dev Set\n",
        "dev_preds = best_model.predict(X_dev)\n",
        "dev_macro_f1 = f1_score(y_dev, dev_preds, average='macro')\n",
        "print(f\"Validation Macro F1 Score (best model): {dev_macro_f1:.4f}\")\n",
        "\n",
        "# Predict on Test Set\n",
        "test_preds = best_model.predict(X_test)\n",
        "test_labels = [id2label[pred] for pred in test_preds]\n",
        "\n",
        "# Save submission\n",
        "output_df = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'label': test_labels\n",
        "})\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "output_df.to_csv('outputs/track_3_test.csv', index=False)\n",
        "\n",
        "print(\"Saved Track 3 submission to outputs/track_3_test.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ba4a31b",
      "metadata": {},
      "source": [
        "# TFIDF + XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8967530",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vectorizing data\n",
            "Vectorization complete.\n",
            "Training XGBoost...\n",
            "[0]\tvalidation_0-mlogloss:1.59660\tvalidation_1-mlogloss:1.59694\n",
            "[1]\tvalidation_0-mlogloss:1.58542\tvalidation_1-mlogloss:1.58588\n",
            "[2]\tvalidation_0-mlogloss:1.57677\tvalidation_1-mlogloss:1.57749\n",
            "[3]\tvalidation_0-mlogloss:1.56816\tvalidation_1-mlogloss:1.56938\n",
            "[4]\tvalidation_0-mlogloss:1.56004\tvalidation_1-mlogloss:1.56188\n",
            "[5]\tvalidation_0-mlogloss:1.55268\tvalidation_1-mlogloss:1.55508\n",
            "[6]\tvalidation_0-mlogloss:1.54618\tvalidation_1-mlogloss:1.54884\n",
            "[7]\tvalidation_0-mlogloss:1.54010\tvalidation_1-mlogloss:1.54338\n",
            "[8]\tvalidation_0-mlogloss:1.53430\tvalidation_1-mlogloss:1.53803\n",
            "[9]\tvalidation_0-mlogloss:1.52921\tvalidation_1-mlogloss:1.53344\n",
            "[10]\tvalidation_0-mlogloss:1.52471\tvalidation_1-mlogloss:1.52969\n",
            "[11]\tvalidation_0-mlogloss:1.52035\tvalidation_1-mlogloss:1.52629\n",
            "[12]\tvalidation_0-mlogloss:1.51612\tvalidation_1-mlogloss:1.52260\n",
            "[13]\tvalidation_0-mlogloss:1.51210\tvalidation_1-mlogloss:1.51908\n",
            "[14]\tvalidation_0-mlogloss:1.50845\tvalidation_1-mlogloss:1.51568\n",
            "[15]\tvalidation_0-mlogloss:1.50501\tvalidation_1-mlogloss:1.51259\n",
            "[16]\tvalidation_0-mlogloss:1.50178\tvalidation_1-mlogloss:1.51010\n",
            "[17]\tvalidation_0-mlogloss:1.49856\tvalidation_1-mlogloss:1.50730\n",
            "[18]\tvalidation_0-mlogloss:1.49551\tvalidation_1-mlogloss:1.50450\n",
            "[19]\tvalidation_0-mlogloss:1.49258\tvalidation_1-mlogloss:1.50206\n",
            "[20]\tvalidation_0-mlogloss:1.49006\tvalidation_1-mlogloss:1.49987\n",
            "[21]\tvalidation_0-mlogloss:1.48742\tvalidation_1-mlogloss:1.49764\n",
            "[22]\tvalidation_0-mlogloss:1.48489\tvalidation_1-mlogloss:1.49552\n",
            "[23]\tvalidation_0-mlogloss:1.48229\tvalidation_1-mlogloss:1.49398\n",
            "[24]\tvalidation_0-mlogloss:1.47992\tvalidation_1-mlogloss:1.49241\n",
            "[25]\tvalidation_0-mlogloss:1.47745\tvalidation_1-mlogloss:1.49065\n",
            "[26]\tvalidation_0-mlogloss:1.47522\tvalidation_1-mlogloss:1.48913\n",
            "[27]\tvalidation_0-mlogloss:1.47306\tvalidation_1-mlogloss:1.48776\n",
            "[28]\tvalidation_0-mlogloss:1.47088\tvalidation_1-mlogloss:1.48622\n",
            "[29]\tvalidation_0-mlogloss:1.46871\tvalidation_1-mlogloss:1.48463\n",
            "[30]\tvalidation_0-mlogloss:1.46655\tvalidation_1-mlogloss:1.48329\n",
            "[31]\tvalidation_0-mlogloss:1.46466\tvalidation_1-mlogloss:1.48183\n",
            "[32]\tvalidation_0-mlogloss:1.46266\tvalidation_1-mlogloss:1.48055\n",
            "[33]\tvalidation_0-mlogloss:1.46081\tvalidation_1-mlogloss:1.47930\n",
            "[34]\tvalidation_0-mlogloss:1.45899\tvalidation_1-mlogloss:1.47827\n",
            "[35]\tvalidation_0-mlogloss:1.45718\tvalidation_1-mlogloss:1.47688\n",
            "[36]\tvalidation_0-mlogloss:1.45554\tvalidation_1-mlogloss:1.47580\n",
            "[37]\tvalidation_0-mlogloss:1.45397\tvalidation_1-mlogloss:1.47484\n",
            "[38]\tvalidation_0-mlogloss:1.45216\tvalidation_1-mlogloss:1.47342\n",
            "[39]\tvalidation_0-mlogloss:1.45054\tvalidation_1-mlogloss:1.47227\n",
            "[40]\tvalidation_0-mlogloss:1.44897\tvalidation_1-mlogloss:1.47144\n",
            "[41]\tvalidation_0-mlogloss:1.44726\tvalidation_1-mlogloss:1.47026\n",
            "[42]\tvalidation_0-mlogloss:1.44569\tvalidation_1-mlogloss:1.46927\n",
            "[43]\tvalidation_0-mlogloss:1.44413\tvalidation_1-mlogloss:1.46833\n",
            "[44]\tvalidation_0-mlogloss:1.44261\tvalidation_1-mlogloss:1.46716\n",
            "[45]\tvalidation_0-mlogloss:1.44118\tvalidation_1-mlogloss:1.46635\n",
            "[46]\tvalidation_0-mlogloss:1.43977\tvalidation_1-mlogloss:1.46563\n",
            "[47]\tvalidation_0-mlogloss:1.43823\tvalidation_1-mlogloss:1.46461\n",
            "[48]\tvalidation_0-mlogloss:1.43678\tvalidation_1-mlogloss:1.46385\n",
            "[49]\tvalidation_0-mlogloss:1.43541\tvalidation_1-mlogloss:1.46309\n",
            "[50]\tvalidation_0-mlogloss:1.43402\tvalidation_1-mlogloss:1.46237\n",
            "[51]\tvalidation_0-mlogloss:1.43256\tvalidation_1-mlogloss:1.46169\n",
            "[52]\tvalidation_0-mlogloss:1.43103\tvalidation_1-mlogloss:1.46089\n",
            "[53]\tvalidation_0-mlogloss:1.42967\tvalidation_1-mlogloss:1.46008\n",
            "[54]\tvalidation_0-mlogloss:1.42809\tvalidation_1-mlogloss:1.45917\n",
            "[55]\tvalidation_0-mlogloss:1.42667\tvalidation_1-mlogloss:1.45880\n",
            "[56]\tvalidation_0-mlogloss:1.42550\tvalidation_1-mlogloss:1.45793\n",
            "[57]\tvalidation_0-mlogloss:1.42422\tvalidation_1-mlogloss:1.45697\n",
            "[58]\tvalidation_0-mlogloss:1.42299\tvalidation_1-mlogloss:1.45635\n",
            "[59]\tvalidation_0-mlogloss:1.42177\tvalidation_1-mlogloss:1.45543\n",
            "[60]\tvalidation_0-mlogloss:1.42046\tvalidation_1-mlogloss:1.45477\n",
            "[61]\tvalidation_0-mlogloss:1.41923\tvalidation_1-mlogloss:1.45409\n",
            "[62]\tvalidation_0-mlogloss:1.41805\tvalidation_1-mlogloss:1.45338\n",
            "[63]\tvalidation_0-mlogloss:1.41673\tvalidation_1-mlogloss:1.45261\n",
            "[64]\tvalidation_0-mlogloss:1.41547\tvalidation_1-mlogloss:1.45209\n",
            "[65]\tvalidation_0-mlogloss:1.41426\tvalidation_1-mlogloss:1.45135\n",
            "[66]\tvalidation_0-mlogloss:1.41306\tvalidation_1-mlogloss:1.45068\n",
            "[67]\tvalidation_0-mlogloss:1.41187\tvalidation_1-mlogloss:1.45009\n",
            "[68]\tvalidation_0-mlogloss:1.41081\tvalidation_1-mlogloss:1.44960\n",
            "[69]\tvalidation_0-mlogloss:1.40975\tvalidation_1-mlogloss:1.44899\n",
            "[70]\tvalidation_0-mlogloss:1.40845\tvalidation_1-mlogloss:1.44855\n",
            "[71]\tvalidation_0-mlogloss:1.40732\tvalidation_1-mlogloss:1.44812\n",
            "[72]\tvalidation_0-mlogloss:1.40624\tvalidation_1-mlogloss:1.44763\n",
            "[73]\tvalidation_0-mlogloss:1.40509\tvalidation_1-mlogloss:1.44707\n",
            "[74]\tvalidation_0-mlogloss:1.40391\tvalidation_1-mlogloss:1.44651\n",
            "[75]\tvalidation_0-mlogloss:1.40283\tvalidation_1-mlogloss:1.44606\n",
            "[76]\tvalidation_0-mlogloss:1.40177\tvalidation_1-mlogloss:1.44551\n",
            "[77]\tvalidation_0-mlogloss:1.40083\tvalidation_1-mlogloss:1.44490\n",
            "[78]\tvalidation_0-mlogloss:1.39979\tvalidation_1-mlogloss:1.44431\n",
            "[79]\tvalidation_0-mlogloss:1.39865\tvalidation_1-mlogloss:1.44377\n",
            "[80]\tvalidation_0-mlogloss:1.39767\tvalidation_1-mlogloss:1.44331\n",
            "[81]\tvalidation_0-mlogloss:1.39654\tvalidation_1-mlogloss:1.44288\n",
            "[82]\tvalidation_0-mlogloss:1.39550\tvalidation_1-mlogloss:1.44236\n",
            "[83]\tvalidation_0-mlogloss:1.39443\tvalidation_1-mlogloss:1.44176\n",
            "[84]\tvalidation_0-mlogloss:1.39341\tvalidation_1-mlogloss:1.44131\n",
            "[85]\tvalidation_0-mlogloss:1.39235\tvalidation_1-mlogloss:1.44086\n",
            "[86]\tvalidation_0-mlogloss:1.39133\tvalidation_1-mlogloss:1.44055\n",
            "[87]\tvalidation_0-mlogloss:1.39027\tvalidation_1-mlogloss:1.43988\n",
            "[88]\tvalidation_0-mlogloss:1.38926\tvalidation_1-mlogloss:1.43945\n",
            "[89]\tvalidation_0-mlogloss:1.38829\tvalidation_1-mlogloss:1.43899\n",
            "[90]\tvalidation_0-mlogloss:1.38735\tvalidation_1-mlogloss:1.43831\n",
            "[91]\tvalidation_0-mlogloss:1.38632\tvalidation_1-mlogloss:1.43798\n",
            "[92]\tvalidation_0-mlogloss:1.38529\tvalidation_1-mlogloss:1.43750\n",
            "[93]\tvalidation_0-mlogloss:1.38439\tvalidation_1-mlogloss:1.43705\n",
            "[94]\tvalidation_0-mlogloss:1.38337\tvalidation_1-mlogloss:1.43648\n",
            "[95]\tvalidation_0-mlogloss:1.38238\tvalidation_1-mlogloss:1.43618\n",
            "[96]\tvalidation_0-mlogloss:1.38145\tvalidation_1-mlogloss:1.43581\n",
            "[97]\tvalidation_0-mlogloss:1.38052\tvalidation_1-mlogloss:1.43518\n",
            "[98]\tvalidation_0-mlogloss:1.37966\tvalidation_1-mlogloss:1.43480\n",
            "[99]\tvalidation_0-mlogloss:1.37874\tvalidation_1-mlogloss:1.43449\n",
            "Evaluating on dev set...\n",
            "Validation Macro F1 Score: 0.3934\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"\\n'n_estimators': [300, 500],\\n'max_depth': [4, 6, 8],\\n'learning_rate': [0.01, 0.05, 0.1],\\n'subsample': [0.7, 0.8, 1.0],\\n'colsample_bytree': [0.7, 0.8, 1.0]\\n\""
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv('../data/train.csv')\n",
        "dev_df = pd.read_csv('../data/dev.csv')\n",
        "test_df = pd.read_csv('../data/test.csv')\n",
        "\n",
        "# Preprocessing\n",
        "full_train_texts = train_df['text'].tolist() + dev_df['text'].tolist()\n",
        "full_train_labels = train_df['label'].tolist() + dev_df['label'].tolist()\n",
        "\n",
        "labels = list(sorted(set(full_train_labels)))\n",
        "label2id = {label: idx for idx, label in enumerate(labels)}\n",
        "id2label = {idx: label for label, idx in label2id.items()}\n",
        "\n",
        "y_train = [label2id[label] for label in train_df['label']]\n",
        "y_dev = [label2id[label] for label in dev_df['label']]\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfVectorizer(\n",
        "    analyzer='char_wb',\n",
        "    ngram_range=(2,6),\n",
        "    max_features=50000\n",
        ")\n",
        "\n",
        "print(\"Vectorizing data\")\n",
        "tfidf.fit(full_train_texts)\n",
        "\n",
        "X_train = tfidf.transform(train_df['text'])\n",
        "X_dev = tfidf.transform(dev_df['text'])\n",
        "X_test = tfidf.transform(test_df['text'])\n",
        "print(\"Vectorization complete.\")\n",
        "\n",
        "# Train XGBoost Classifier\n",
        "print(\"Training XGBoost...\")\n",
        "\n",
        "model = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=len(labels),\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbosity=1\n",
        ")\n",
        "\n",
        "eval_set = [(X_train, y_train), (X_dev, y_dev)]\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=eval_set,\n",
        "    # eval_metric='mlogloss',\n",
        "    # early_stopping_rounds=10,  # ⛔ Stop if no dev improvement in 10 rounds\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Dev Set Evaluation\n",
        "print(\"Evaluating on dev set...\")\n",
        "dev_preds = model.predict(X_dev)\n",
        "dev_macro_f1 = f1_score(y_dev, dev_preds, average='macro')\n",
        "print(f\"Validation Macro F1 Score: {dev_macro_f1:.4f}\")\n",
        "\n",
        "# # Predict on Test Set\n",
        "# test_preds = model.predict(X_test)\n",
        "# test_labels = [id2label[pred] for pred in test_preds]\n",
        "\n",
        "# # Save submission\n",
        "# output_df = pd.DataFrame({\n",
        "#     'id': test_df['id'],\n",
        "#     'label': test_labels\n",
        "# })\n",
        "# os.makedirs('outputs', exist_ok=True)\n",
        "# output_df.to_csv('outputs/track_3_test.csv', index=False)\n",
        "\n",
        "# print(\"Saved Track 3 submission to outputs/track_3_test.csv\")\n",
        "\n",
        "\"\"\"\n",
        "'n_estimators': [300, 500],\n",
        "'max_depth': [4, 6, 8],\n",
        "'learning_rate': [0.01, 0.05, 0.1],\n",
        "'subsample': [0.7, 0.8, 1.0],\n",
        "'colsample_bytree': [0.7, 0.8, 1.0]\n",
        "\"\"\"\n",
        "\n",
        "# score = 0.3934"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbd22060",
      "metadata": {},
      "source": [
        "# Old"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1d042f12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d042f12",
        "outputId": "22dc862b-6f85-4192-f652-e055f0d6effa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuning Random Forest hyperparameters:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search: 100%|██████████| 1/1 [15:44<00:00, 944.87s/combo]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best params: {'n_estimators': 200, 'max_depth': None, 'max_features': 'sqrt'} with CV macro-F1 = 0.2862\n",
            "DEV Macro F1: 0.2918208850519727\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Load data\n",
        "# ----------------\n",
        "# Read CSVs into pandas DataFrames. 'test' has no labels.\n",
        "train = pd.read_csv(\"train.csv\")  # Training set with labels\n",
        "dev = pd.read_csv(\"dev.csv\")      # Development set with labels\n",
        "test = pd.read_csv(\"test.csv\")    # Test set without labels\n",
        "\n",
        "# 2. Vectorize text\n",
        "# --------------------\n",
        "# Convert raw text into TF-IDF feature vectors.\n",
        "# - ngram_range=(2,6): consider character n-grams of length 2 to 6.\n",
        "# - min_df=5: ignore infrequent n-grams to reduce noise.\n",
        "vectorizer = TfidfVectorizer(ngram_range=(2,6), min_df=5)\n",
        "X_train = vectorizer.fit_transform(train['text'])\n",
        "y_train = train['label']\n",
        "X_dev = vectorizer.transform(dev['text'])\n",
        "y_dev = dev['label']\n",
        "X_test = vectorizer.transform(test['text'])\n",
        "\n",
        "# 3. Hyperparameter tuning with progress bar\n",
        "# --------------------------------------------\n",
        "# Define grid of Random Forest hyperparameters:\n",
        "# - n_estimators: number of trees in the forest\n",
        "# - max_depth: maximum depth of each tree\n",
        "# - max_features: number of features to consider at each split\n",
        "\n",
        "# param_grid = {\n",
        "#     'n_estimators': [100, 200, 500],\n",
        "#     'max_depth': [None, 10, 20],\n",
        "#     'max_features': ['sqrt', 'log2', 0.3]\n",
        "# }\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [200],\n",
        "    'max_depth': [None],\n",
        "    'max_features': ['sqrt']\n",
        "}\n",
        "\n",
        "# Create a list of all parameter combinations\n",
        "import itertools\n",
        "param_list = list(itertools.product(\n",
        "    param_grid['n_estimators'],\n",
        "    param_grid['max_depth'],\n",
        "    param_grid['max_features']\n",
        "))\n",
        "\n",
        "best_score = 0\n",
        "best_params = None\n",
        "print(\"Tuning Random Forest hyperparameters:\")\n",
        "for n_est, depth, feat in tqdm(param_list, desc=\"Grid Search\", unit=\"combo\"):\n",
        "    # Initialize a Random Forest with current hyperparameters\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=n_est,\n",
        "        max_depth=depth,\n",
        "        max_features=feat,\n",
        "        oob_score=False,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    # 3-fold cross-validation for macro-F1 on TRAIN\n",
        "    scores = cross_val_score(\n",
        "        rf, X_train, y_train,\n",
        "        scoring='f1_macro',\n",
        "        cv=3,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    mean_score = scores.mean()\n",
        "    # Update best parameters if current is better\n",
        "    if mean_score > best_score:\n",
        "        best_score = mean_score\n",
        "        best_params = {'n_estimators': n_est, 'max_depth': depth, 'max_features': feat}\n",
        "\n",
        "print(f\"\\nBest params: {best_params} with CV macro-F1 = {best_score:.4f}\")\n",
        "\n",
        "# 4. Train best Random Forest on full TRAIN set\n",
        "# ------------------------------------------------\n",
        "best_rf = RandomForestClassifier(\n",
        "    **best_params,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "best_rf.fit(X_train, y_train)\n",
        "\n",
        "# 5. Evaluate on DEV set\n",
        "# -----------------------\n",
        "dev_preds = best_rf.predict(X_dev)\n",
        "print(\"DEV Macro F1:\", f1_score(y_dev, dev_preds, average='macro'))\n",
        "\n",
        "# 6. (Optional) Retrain on TRAIN + DEV and predict TEST\n",
        "# ------------------------------------------------------\n",
        "# all_texts = pd.concat([train['text'], dev['text']])\n",
        "# all_labels = pd.concat([train['label'], dev['label']])\n",
        "# X_all = vectorizer.fit_transform(all_texts)\n",
        "# best_rf.fit(X_all, all_labels)\n",
        "# test_preds = best_rf.predict(X_test)\n",
        "# submission = pd.DataFrame({'id': test['id'], 'label': test_preds})\n",
        "# submission.to_csv('track_1_test.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dYPEjrX9LOgl",
      "metadata": {
        "id": "dYPEjrX9LOgl"
      },
      "source": [
        "# Linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d25634",
      "metadata": {
        "id": "92d25634",
        "outputId": "d332e970-2a3b-4428-d052-8ef8bbd5d3c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuning regularization strength C:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search - C values: 100%|██████████| 4/4 [00:09<00:00,  2.49s/value]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best C found: 1 with CV macro-F1 = 0.3164\n",
            "DEV Macro F1: 0.3149562265024328\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Load data\n",
        "# ----------------\n",
        "train = pd.read_csv(\"train.csv\")  # Training set\n",
        "dev = pd.read_csv(\"dev.csv\")      # Development/validation set\n",
        "test = pd.read_csv(\"test.csv\")    # Test set (unlabeled)\n",
        "\n",
        "# 2. Vectorize text\n",
        "# --------------------\n",
        "vectorizer = TfidfVectorizer(ngram_range=(2,6), min_df=5)\n",
        "X_train = vectorizer.fit_transform(train['text'])\n",
        "y_train = train['label']\n",
        "X_dev = vectorizer.transform(dev['text'])\n",
        "y_dev = dev['label']\n",
        "X_test = vectorizer.transform(test['text'])\n",
        "\n",
        "# 3. Manual hyperparameter tuning with progress bar\n",
        "# ---------------------------------------------------\n",
        "# Define grid of regularization strengths\n",
        "param_C = [0.01, 0.1, 1, 10]\n",
        "best_score = 0\n",
        "best_C = None\n",
        "print(\"Tuning regularization strength C:\")\n",
        "for C in tqdm(param_C, desc=\"Grid Search - C values\", unit=\"value\"):\n",
        "    # Initialize model with current C\n",
        "    lr = LogisticRegression(\n",
        "        penalty='l2',\n",
        "        solver='saga',\n",
        "        max_iter=1000,\n",
        "        C=C,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "    # Perform 3-fold CV on training set, scoring macro-F1\n",
        "    scores = cross_val_score(\n",
        "        lr, X_train, y_train,\n",
        "        scoring='f1_macro',\n",
        "        cv=3,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    mean_score = scores.mean()\n",
        "    if mean_score > best_score:\n",
        "        best_score = mean_score\n",
        "        best_C = C\n",
        "        best_scores = scores\n",
        "\n",
        "print(f\"\\nBest C found: {best_C} with CV macro-F1 = {best_score:.4f}\")\n",
        "\n",
        "# Train best model on full TRAIN\n",
        "best_lr = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    solver='saga',\n",
        "    max_iter=1000,\n",
        "    C=best_C,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "best_lr.fit(X_train, y_train)\n",
        "\n",
        "# 4. Evaluate on DEV set\n",
        "# -----------------------\n",
        "dev_preds = best_lr.predict(X_dev)\n",
        "print(\"DEV Macro F1:\", f1_score(y_dev, dev_preds, average='macro'))\n",
        "\n",
        "# 5. (Optional) Retrain on TRAIN + DEV and predict TEST\n",
        "# ------------------------------------------------------\n",
        "# all_texts = pd.concat([train['text'], dev['text']])\n",
        "# all_labels = pd.concat([train['label'], dev['label']])\n",
        "# X_all = vectorizer.fit_transform(all_texts)\n",
        "# best_lr.fit(X_all, all_labels)\n",
        "# test_preds = best_lr.predict(X_test)\n",
        "\n",
        "# # Save submission\n",
        "# submission = pd.DataFrame({'id': test['id'], 'label': test_preds})\n",
        "# submission.to_csv('track_1_test.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
