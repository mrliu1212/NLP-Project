{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 2. Clone your repo (public example—no auth needed)\n",
        "!git clone https://github.com/mrliu1212/NLP-Project.git"
      ],
      "metadata": {
        "id": "9xWzRP7UK7DE",
        "outputId": "5d9fa1f8-02cf-46db-9392-fc44fab1fc80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9xWzRP7UK7DE",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP-Project'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 22 (delta 4), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (22/22), 3.17 MiB | 5.10 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. cd into it\n",
        "%cd NLP-Project\n",
        "# 4. List all branches to confirm\n",
        "!git branch -a"
      ],
      "metadata": {
        "id": "h2yAOK3pLA5n",
        "outputId": "3ee25894-0f58-4539-c194-876bab505fe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "h2yAOK3pLA5n",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NLP-Project\n",
            "* \u001b[32mmain\u001b[m\n",
            "  \u001b[31mremotes/origin/Classification\u001b[m\n",
            "  \u001b[31mremotes/origin/Final-Project\u001b[m\n",
            "  \u001b[31mremotes/origin/HEAD\u001b[m -> origin/main\n",
            "  \u001b[31mremotes/origin/main\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout remotes/origin/Classification"
      ],
      "metadata": {
        "id": "cAbaaq62LDMt",
        "outputId": "a5c06b72-61ff-4930-bf96-638981a0bcee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cAbaaq62LDMt",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: switching to 'remotes/origin/Classification'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 104764d Created using Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1d042f12",
      "metadata": {
        "id": "1d042f12",
        "outputId": "22dc862b-6f85-4192-f652-e055f0d6effa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning Random Forest hyperparameters:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Grid Search: 100%|██████████| 1/1 [15:44<00:00, 944.87s/combo]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best params: {'n_estimators': 200, 'max_depth': None, 'max_features': 'sqrt'} with CV macro-F1 = 0.2862\n",
            "DEV Macro F1: 0.2918208850519727\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Load data\n",
        "# ----------------\n",
        "# Read CSVs into pandas DataFrames. 'test' has no labels.\n",
        "train = pd.read_csv(\"train.csv\")  # Training set with labels\n",
        "dev = pd.read_csv(\"dev.csv\")      # Development set with labels\n",
        "test = pd.read_csv(\"test.csv\")    # Test set without labels\n",
        "\n",
        "# 2. Vectorize text\n",
        "# --------------------\n",
        "# Convert raw text into TF-IDF feature vectors.\n",
        "# - ngram_range=(2,6): consider character n-grams of length 2 to 6.\n",
        "# - min_df=5: ignore infrequent n-grams to reduce noise.\n",
        "vectorizer = TfidfVectorizer(ngram_range=(2,6), min_df=5)\n",
        "X_train = vectorizer.fit_transform(train['text'])\n",
        "y_train = train['label']\n",
        "X_dev = vectorizer.transform(dev['text'])\n",
        "y_dev = dev['label']\n",
        "X_test = vectorizer.transform(test['text'])\n",
        "\n",
        "# 3. Hyperparameter tuning with progress bar\n",
        "# --------------------------------------------\n",
        "# Define grid of Random Forest hyperparameters:\n",
        "# - n_estimators: number of trees in the forest\n",
        "# - max_depth: maximum depth of each tree\n",
        "# - max_features: number of features to consider at each split\n",
        "\n",
        "# param_grid = {\n",
        "#     'n_estimators': [100, 200, 500],\n",
        "#     'max_depth': [None, 10, 20],\n",
        "#     'max_features': ['sqrt', 'log2', 0.3]\n",
        "# }\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [200],\n",
        "    'max_depth': [None],\n",
        "    'max_features': ['sqrt']\n",
        "}\n",
        "\n",
        "# Create a list of all parameter combinations\n",
        "import itertools\n",
        "param_list = list(itertools.product(\n",
        "    param_grid['n_estimators'],\n",
        "    param_grid['max_depth'],\n",
        "    param_grid['max_features']\n",
        "))\n",
        "\n",
        "best_score = 0\n",
        "best_params = None\n",
        "print(\"Tuning Random Forest hyperparameters:\")\n",
        "for n_est, depth, feat in tqdm(param_list, desc=\"Grid Search\", unit=\"combo\"):\n",
        "    # Initialize a Random Forest with current hyperparameters\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=n_est,\n",
        "        max_depth=depth,\n",
        "        max_features=feat,\n",
        "        oob_score=False,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    # 3-fold cross-validation for macro-F1 on TRAIN\n",
        "    scores = cross_val_score(\n",
        "        rf, X_train, y_train,\n",
        "        scoring='f1_macro',\n",
        "        cv=3,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    mean_score = scores.mean()\n",
        "    # Update best parameters if current is better\n",
        "    if mean_score > best_score:\n",
        "        best_score = mean_score\n",
        "        best_params = {'n_estimators': n_est, 'max_depth': depth, 'max_features': feat}\n",
        "\n",
        "print(f\"\\nBest params: {best_params} with CV macro-F1 = {best_score:.4f}\")\n",
        "\n",
        "# 4. Train best Random Forest on full TRAIN set\n",
        "# ------------------------------------------------\n",
        "best_rf = RandomForestClassifier(\n",
        "    **best_params,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "best_rf.fit(X_train, y_train)\n",
        "\n",
        "# 5. Evaluate on DEV set\n",
        "# -----------------------\n",
        "dev_preds = best_rf.predict(X_dev)\n",
        "print(\"DEV Macro F1:\", f1_score(y_dev, dev_preds, average='macro'))\n",
        "\n",
        "# 6. (Optional) Retrain on TRAIN + DEV and predict TEST\n",
        "# ------------------------------------------------------\n",
        "# all_texts = pd.concat([train['text'], dev['text']])\n",
        "# all_labels = pd.concat([train['label'], dev['label']])\n",
        "# X_all = vectorizer.fit_transform(all_texts)\n",
        "# best_rf.fit(X_all, all_labels)\n",
        "# test_preds = best_rf.predict(X_test)\n",
        "# submission = pd.DataFrame({'id': test['id'], 'label': test_preds})\n",
        "# submission.to_csv('track_1_test.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear regression"
      ],
      "metadata": {
        "id": "dYPEjrX9LOgl"
      },
      "id": "dYPEjrX9LOgl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d25634",
      "metadata": {
        "id": "92d25634",
        "outputId": "d332e970-2a3b-4428-d052-8ef8bbd5d3c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuning regularization strength C:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search - C values: 100%|██████████| 4/4 [00:09<00:00,  2.49s/value]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best C found: 1 with CV macro-F1 = 0.3164\n",
            "DEV Macro F1: 0.3149562265024328\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Load data\n",
        "# ----------------\n",
        "train = pd.read_csv(\"train.csv\")  # Training set\n",
        "dev = pd.read_csv(\"dev.csv\")      # Development/validation set\n",
        "test = pd.read_csv(\"test.csv\")    # Test set (unlabeled)\n",
        "\n",
        "# 2. Vectorize text\n",
        "# --------------------\n",
        "vectorizer = TfidfVectorizer(ngram_range=(2,6), min_df=5)\n",
        "X_train = vectorizer.fit_transform(train['text'])\n",
        "y_train = train['label']\n",
        "X_dev = vectorizer.transform(dev['text'])\n",
        "y_dev = dev['label']\n",
        "X_test = vectorizer.transform(test['text'])\n",
        "\n",
        "# 3. Manual hyperparameter tuning with progress bar\n",
        "# ---------------------------------------------------\n",
        "# Define grid of regularization strengths\n",
        "param_C = [0.01, 0.1, 1, 10]\n",
        "best_score = 0\n",
        "best_C = None\n",
        "print(\"Tuning regularization strength C:\")\n",
        "for C in tqdm(param_C, desc=\"Grid Search - C values\", unit=\"value\"):\n",
        "    # Initialize model with current C\n",
        "    lr = LogisticRegression(\n",
        "        penalty='l2',\n",
        "        solver='saga',\n",
        "        max_iter=1000,\n",
        "        C=C,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "    # Perform 3-fold CV on training set, scoring macro-F1\n",
        "    scores = cross_val_score(\n",
        "        lr, X_train, y_train,\n",
        "        scoring='f1_macro',\n",
        "        cv=3,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    mean_score = scores.mean()\n",
        "    if mean_score > best_score:\n",
        "        best_score = mean_score\n",
        "        best_C = C\n",
        "        best_scores = scores\n",
        "\n",
        "print(f\"\\nBest C found: {best_C} with CV macro-F1 = {best_score:.4f}\")\n",
        "\n",
        "# Train best model on full TRAIN\n",
        "best_lr = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    solver='saga',\n",
        "    max_iter=1000,\n",
        "    C=best_C,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "best_lr.fit(X_train, y_train)\n",
        "\n",
        "# 4. Evaluate on DEV set\n",
        "# -----------------------\n",
        "dev_preds = best_lr.predict(X_dev)\n",
        "print(\"DEV Macro F1:\", f1_score(y_dev, dev_preds, average='macro'))\n",
        "\n",
        "# 5. (Optional) Retrain on TRAIN + DEV and predict TEST\n",
        "# ------------------------------------------------------\n",
        "# all_texts = pd.concat([train['text'], dev['text']])\n",
        "# all_labels = pd.concat([train['label'], dev['label']])\n",
        "# X_all = vectorizer.fit_transform(all_texts)\n",
        "# best_lr.fit(X_all, all_labels)\n",
        "# test_preds = best_lr.predict(X_test)\n",
        "\n",
        "# # Save submission\n",
        "# submission = pd.DataFrame({'id': test['id'], 'label': test_preds})\n",
        "# submission.to_csv('track_1_test.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}